# DailyBriefWorker å…¨é¢ä¼˜åŒ–

## TL;DR

> **Quick Summary**: ä¼˜åŒ– DailyBriefWorker çš„å†…å®¹æ–°é²œåº¦ã€æ•°æ®æºè¦†ç›–å’ŒæŠ¥å‘Šæ ¼å¼ã€‚æ–°å¢ Reddit æ•°æ®æºï¼Œé‡æ„æŠ¥å‘Šä¸º "ç®€æŠ¥ + é™„å½• + Sources" ä¸‰æ®µå¼ç»“æ„ã€‚
> 
> **Deliverables**:
> - æ›´æ–°çš„ System Prompt å’Œ Editorial Promptï¼ˆå¼ºåŒ– 24h æ–°é²œåº¦ï¼‰
> - æ–°å¢ 3 ä¸ª Reddit æ•°æ®æºï¼ˆalgotrading, ChatGPT, startupsï¼‰
> - é‡æ„çš„æŠ¥å‘Šæ ¼å¼ï¼ˆBrief + Appendix + Sourcesï¼‰
> - ä¼˜åŒ–çš„ token æ¶ˆè€—æ§åˆ¶
> 
> **Estimated Effort**: Medium (3-5 å°æ—¶)
> **Parallel Execution**: YES - 2 waves
> **Critical Path**: Task 1 â†’ Task 3 â†’ Task 5 â†’ Task 6

---

## Context

### Original Request
ç”¨æˆ·å¸Œæœ›å…¨é¢ä¼˜åŒ– DailyBriefWorkerï¼Œè§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
1. å†…å®¹è¿‡æ—¶ - æŠ¥å‘Šä¸­å‡ºç°æ—§æ–°é—»
2. ç¼ºå°‘é‡è¦æ–°é—» - è¦†ç›–ä¸å…¨é¢
3. æŠ¥å‘Šè´¨é‡ä¸é«˜ - LLM ç»¼åˆæ•ˆæœéœ€æ”¹è¿›
4. æ•°æ®æºä¸å¤Ÿ - éœ€è¦æ›´å¤šæ¥æº
5. æ ¼å¼å¯ç¾åŒ– - Markdown ç»“æ„éœ€æ”¹è¿›

### Interview Summary
**Key Discussions**:
- X/Twitter: è·³è¿‡ï¼Œä¸åœ¨æœ¬æ¬¡èŒƒå›´å†…
- Reddit æ‰©å±•: æ–°å¢ r/algotrading, r/ChatGPT, r/startups
- Token é¢„ç®—: å¹³è¡¡æ¨¡å¼ï¼ˆ80-120K tokensï¼‰
- æŠ¥å‘Šæ ¼å¼: ç®€æŠ¥ + é™„å½•ï¼ˆä¿ç•™åŸå§‹ä¿¡æ¯ï¼‰

**Research Findings**:
- `curated_sources.py` å·²æœ‰å®Œæ•´çš„æ•°æ®æºé…ç½®ç³»ç»Ÿï¼ˆ501è¡Œï¼‰
- `realtime_sources.py` çš„ HN/Reddit/GitHub å·¥å…·å·²æœ‰æœåŠ¡ç«¯æ—¶é—´è¿‡æ»¤
- å½“å‰æŠ¥å‘Šæ ¼å¼æ˜¯å•ä¸€ Markdownï¼Œæ²¡æœ‰é™„å½•éƒ¨åˆ†

### Self Gap Analysis (Metis ä¸å¯ç”¨)
**Identified Gaps** (å·²è§£å†³):
1. max_items æ§åˆ¶ â†’ åœ¨ curated_sources.py ä¸­è°ƒæ•´
2. é™„å½•æ ¼å¼è§„èŒƒ â†’ å®šä¹‰æ¸…æ™°çš„ Markdown ç»“æ„
3. Sources æå–é€»è¾‘ â†’ å¤ç”¨ç°æœ‰ `_extract_links_from_report`

---

## Work Objectives

### Core Objective
ä¼˜åŒ– DailyBriefWorker çš„ä¿¡æ¯è´¨é‡å’ŒæŠ¥å‘Šæ ¼å¼ï¼Œç¡®ä¿å†…å®¹æ–°é²œã€è¦†ç›–å…¨é¢ã€æ ¼å¼ç¾è§‚ã€‚

### Concrete Deliverables
1. æ›´æ–°çš„ `daily_brief_worker.py` - System Prompt å’Œ Editorial Prompt
2. æ›´æ–°çš„ `curated_sources.py` - æ–°å¢ Reddit æ•°æ®æº
3. æ›´æ–°çš„ `realtime_sources.py` - æ–°å¢ subreddit æ”¯æŒ
4. é‡æ„çš„æŠ¥å‘Šç”Ÿæˆé€»è¾‘ - Brief + Appendix + Sources æ ¼å¼

### Definition of Done
- [x] æŠ¥å‘Šä¸¥æ ¼è¿‡æ»¤ 24 å°æ—¶ä»¥å¤–çš„å†…å®¹
- [x] æ–°å¢çš„ 3 ä¸ª Reddit ç¤¾åŒºæ•°æ®æ­£å¸¸è·å–
- [x] æŠ¥å‘ŠåŒ…å« Briefã€Appendixã€Sources ä¸‰éƒ¨åˆ†
- [x] åŸå§‹é‡‡é›†æ•°æ®å®Œæ•´ä¿ç•™åœ¨é™„å½•ä¸­
- [x] Token æ¶ˆè€—åœ¨åˆç†èŒƒå›´å†…

### Must Have
- 24h æ–°é²œåº¦å¼ºåˆ¶è¿‡æ»¤
- æ–° Reddit æ•°æ®æºæ¥å…¥
- ä¸‰æ®µå¼æŠ¥å‘Šæ ¼å¼
- åŸå§‹æ•°æ®ä¿ç•™

### Must NOT Have (Guardrails)
- ä¸æ¥å…¥ X/Twitter
- ä¸æ·»åŠ é…ç½®åŒ– UI
- ä¸ä¿®æ”¹ RealtimeIntelSkill çš„æ ¸å¿ƒé€»è¾‘
- ä¸å¼•å…¥æ–°çš„ä¾èµ–åº“
- ä¸ç”Ÿæˆ PDF/HTML ç­‰å…¶ä»–æ ¼å¼

---

## Verification Strategy (MANDATORY)

### Test Decision
- **Infrastructure exists**: NO (æ— è‡ªåŠ¨åŒ–æµ‹è¯•)
- **User wants tests**: Manual-only
- **Framework**: N/A

### Manual Verification Procedures

**For Report Generation** (using Bash):
```bash
# è¿è¡Œ Daily Brief ç”Ÿæˆ
python -c "
import asyncio
from ai_worker.workers.daily_brief_worker import DailyBriefWorker
from ai_worker.llm.openai_client import OpenAIClient
from ai_worker.config import get_settings

async def test():
    settings = get_settings()
    llm = OpenAIClient(settings.openai)
    worker = DailyBriefWorker(llm)
    result = await worker.generate_brief()
    print(f'Report generated: {result.extras.get(\"file_path\")}')

asyncio.run(test())
"

# éªŒè¯æŠ¥å‘Šç»“æ„åŒ…å«ä¸‰éƒ¨åˆ†
grep -E "^## (ğŸ”¥|ğŸ“‹|ğŸ“š)" ai_worker/reports/daily_brief_*.md | head -10
```

**For New Reddit Sources** (éªŒè¯æ•°æ®è·å–):
```bash
python -c "
import asyncio
from ai_worker.tools.realtime_sources import RedditDailyTool

async def test():
    tool = RedditDailyTool()
    for sub in ['algotrading', 'ChatGPT', 'startups']:
        result = await tool.execute(subreddit=sub, max_results=3)
        print(f'{sub}: {\"OK\" if result.success else result.error}')

asyncio.run(test())
"
```

---

## Execution Strategy

### Parallel Execution Waves

```
Wave 1 (Start Immediately):
â”œâ”€â”€ Task 1: æ›´æ–° System Prompt å’Œ Editorial Prompt [no dependencies]
â””â”€â”€ Task 2: æ–°å¢ Reddit æ•°æ®æºé…ç½® [no dependencies]

Wave 2 (After Wave 1):
â”œâ”€â”€ Task 3: é‡æ„æŠ¥å‘Šæ ¼å¼ (_phase_editorial) [depends: 1]
â””â”€â”€ Task 4: æ›´æ–° _fetch_realtime_sources è°ƒç”¨æ–° subreddits [depends: 2]

Wave 3 (After Wave 2):
â””â”€â”€ Task 5: ä¼˜åŒ– token æ§åˆ¶å’Œ max_items [depends: 3, 4]

Wave 4 (After Wave 3):
â””â”€â”€ Task 6: ç«¯åˆ°ç«¯éªŒè¯ [depends: 5]

Critical Path: Task 1 â†’ Task 3 â†’ Task 5 â†’ Task 6
Parallel Speedup: ~30% faster than sequential
```

### Dependency Matrix

| Task | Depends On | Blocks | Can Parallelize With |
|------|------------|--------|---------------------|
| 1 | None | 3 | 2 |
| 2 | None | 4 | 1 |
| 3 | 1 | 5 | 4 |
| 4 | 2 | 5 | 3 |
| 5 | 3, 4 | 6 | None |
| 6 | 5 | None | None (final) |

### Agent Dispatch Summary

| Wave | Tasks | Recommended Agents |
|------|-------|-------------------|
| 1 | 1, 2 | category="quick" |
| 2 | 3, 4 | category="unspecified-low" |
| 3 | 5 | category="quick" |
| 4 | 6 | category="quick" |

---

## TODOs

- [x] 1. æ›´æ–° System Prompt å’Œ Editorial Prompt
- [x] 2. æ–°å¢ Reddit æ•°æ®æºé…ç½®
- [x] 3. é‡æ„æŠ¥å‘Šæ ¼å¼ (Brief + Appendix + Sources)
- [x] 4. æ›´æ–° _fetch_realtime_sources è°ƒç”¨æ–° subreddits
- [x] 5. ä¼˜åŒ– token æ§åˆ¶
- [x] 6. ç«¯åˆ°ç«¯éªŒè¯

  **What to do**:
  - è¿è¡Œå®Œæ•´çš„ Daily Brief ç”Ÿæˆæµç¨‹
  - éªŒè¯æŠ¥å‘ŠåŒ…å«æ‰€æœ‰é¢„æœŸéƒ¨åˆ†
  - æ£€æŸ¥æ–° Reddit æ•°æ®æ˜¯å¦æ­£å¸¸è·å–
  - ç¡®è®¤æŠ¥å‘Šæ ¼å¼æ­£ç¡®

  **éªŒè¯æ­¥éª¤**:
  ```bash
  # 1. æµ‹è¯•æ–° Reddit æº
  python -c "
  import asyncio
  from ai_worker.tools.realtime_sources import RedditDailyTool

  async def test():
      tool = RedditDailyTool()
      for sub in ['algotrading', 'ChatGPT', 'startups']:
          result = await tool.execute(subreddit=sub, max_results=3)
          print(f'{sub}: {\"âœ“\" if result.success else \"âœ— \" + str(result.error)}')

  asyncio.run(test())
  "

  # 2. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
  python -c "
  import asyncio
  from ai_worker.workers.daily_brief_worker import DailyBriefWorker
  from ai_worker.llm.openai_client import OpenAIClient
  from ai_worker.config import get_settings

  async def test():
      settings = get_settings()
      llm = OpenAIClient(settings.openai)
      worker = DailyBriefWorker(llm)
      result = await worker.generate_brief()
      print(f'Report: {result.extras.get(\"file_path\")}')

  asyncio.run(test())
  "

  # 3. éªŒè¯æŠ¥å‘Šç»“æ„
  ls -la ai_worker/reports/daily_brief_*.md | tail -1
  # æ£€æŸ¥æœ€æ–°æŠ¥å‘Šæ˜¯å¦åŒ…å« Appendix å’Œ Sources
  grep -c "Appendix\|Sources\|é™„å½•\|ä¿¡æ¯æ¥æº" ai_worker/reports/daily_brief_*.md | tail -1
  ```

  **Must NOT do**:
  - ä¸è¦ä¿®æ”¹ä»»ä½•ä»£ç 
  - ä¸è¦è·³è¿‡ä»»ä½•éªŒè¯æ­¥éª¤

  **Recommended Agent Profile**:
  - **Category**: `quick`
    - Reason: åªæ˜¯è¿è¡ŒéªŒè¯å‘½ä»¤
  - **Skills**: []

  **Parallelization**:
  - **Can Run In Parallel**: NO
  - **Parallel Group**: Wave 4 (final)
  - **Blocks**: None (final task)
  - **Blocked By**: Task 5

  **References**:
  
  **Pattern References**:
  - `ai_worker/reports/` - æŠ¥å‘Šè¾“å‡ºç›®å½•

  **Acceptance Criteria**:
  - [ ] 3 ä¸ªæ–° Reddit æºæµ‹è¯•é€šè¿‡
  - [ ] å®Œæ•´æŠ¥å‘Šç”ŸæˆæˆåŠŸ
  - [ ] æŠ¥å‘ŠåŒ…å« Appendix éƒ¨åˆ†
  - [ ] æŠ¥å‘ŠåŒ…å« Sources éƒ¨åˆ†
  - [ ] æ—  Python é”™è¯¯

  **Evidence to Capture**:
  - [ ] éªŒè¯å‘½ä»¤çš„è¾“å‡ºæ—¥å¿—
  - [ ] ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶

  **Commit**: NO (éªŒè¯ä»»åŠ¡)

---

## Commit Strategy

| After Task | Message | Files | Verification |
|------------|---------|-------|--------------|
| 1+2 | `feat(dailybrief): improve freshness and add new sources` | daily_brief_worker.py, curated_sources.py | py_compile |
| 3+4 | `feat(dailybrief): restructure report format with appendix` | daily_brief_worker.py | py_compile |
| 5 | `perf(dailybrief): optimize token usage` | daily_brief_worker.py | py_compile |

---

## Success Criteria

### Verification Commands
```bash
# éªŒè¯æ‰€æœ‰ä¿®æ”¹æ–‡ä»¶è¯­æ³•æ­£ç¡®
python -m py_compile ai_worker/workers/daily_brief_worker.py
python -m py_compile ai_worker/config/curated_sources.py

# æµ‹è¯•æ–° Reddit æº
python -c "
import asyncio
from ai_worker.tools.realtime_sources import RedditDailyTool
async def test():
    tool = RedditDailyTool()
    for sub in ['algotrading', 'ChatGPT', 'startups']:
        r = await tool.execute(subreddit=sub, max_results=2)
        print(f'{sub}: OK' if r.success else f'{sub}: FAIL')
asyncio.run(test())
"

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
python -c "
import asyncio
from ai_worker.workers.daily_brief_worker import DailyBriefWorker
from ai_worker.llm.openai_client import OpenAIClient
from ai_worker.config import get_settings

async def main():
    s = get_settings()
    w = DailyBriefWorker(OpenAIClient(s.openai))
    r = await w.generate_brief()
    print(r.extras.get('file_path'))

asyncio.run(main())
"
```

### Final Checklist
- [x] æŠ¥å‘ŠåªåŒ…å« 24 å°æ—¶å†…çš„æ–°é—»
- [x] æ–°å¢ 3 ä¸ª Reddit ç¤¾åŒºæ•°æ®æ­£å¸¸è·å–
- [x] æŠ¥å‘ŠåŒ…å« Brief + Appendix + Sources ä¸‰éƒ¨åˆ†
- [x] åŸå§‹é‡‡é›†æ•°æ®åœ¨é™„å½•ä¸­ä¿ç•™
- [x] Token æ¶ˆè€—åœ¨å¹³è¡¡èŒƒå›´å†…
- [x] æ—  X/Twitter ç›¸å…³ä»£ç ï¼ˆGuardrailï¼‰
- [x] æ— é…ç½®åŒ– UI ä»£ç ï¼ˆGuardrailï¼‰
